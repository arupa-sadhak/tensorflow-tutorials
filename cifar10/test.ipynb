{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import images\n",
    "filenames = ['../datas/label%d.txt'%_ for _ in range(10)]\n",
    "reader = images.Reader(filenames, batch_size=128, width=32, height=32, filetype='png', min_after_dequeue=1)\n",
    "batch = reader.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cifar10_architecture import Cifar10Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[training] step:0000, loss:6.381176 accuracy:0.085938 (341.5 examples/sec; 0.375 sec/batch)\n",
      "[training] step:0010, loss:5.188675 accuracy:0.148438 (666.7 examples/sec; 0.192 sec/batch)\n",
      "[training] step:0020, loss:4.422109 accuracy:0.148438 (647.4 examples/sec; 0.198 sec/batch)\n",
      "[training] step:0030, loss:3.703641 accuracy:0.250000 (637.4 examples/sec; 0.201 sec/batch)\n",
      "[training] step:0040, loss:3.459042 accuracy:0.203125 (682.0 examples/sec; 0.188 sec/batch)\n",
      "[training] step:0050, loss:3.085935 accuracy:0.218750 (642.4 examples/sec; 0.199 sec/batch)\n",
      "[training] step:0060, loss:2.728595 accuracy:0.226562 (681.9 examples/sec; 0.188 sec/batch)\n",
      "[training] step:0070, loss:2.477201 accuracy:0.398438 (674.0 examples/sec; 0.190 sec/batch)\n",
      "[training] step:0080, loss:2.428601 accuracy:0.226562 (717.8 examples/sec; 0.178 sec/batch)\n",
      "[training] step:0090, loss:2.277812 accuracy:0.320312 (672.1 examples/sec; 0.190 sec/batch)\n",
      "[training] step:0100, loss:2.319672 accuracy:0.304688 (644.2 examples/sec; 0.199 sec/batch)\n",
      "[training] step:0110, loss:2.273779 accuracy:0.234375 (687.1 examples/sec; 0.186 sec/batch)\n",
      "[training] step:0120, loss:2.215114 accuracy:0.265625 (627.5 examples/sec; 0.204 sec/batch)\n",
      "[training] step:0130, loss:2.249048 accuracy:0.265625 (671.6 examples/sec; 0.191 sec/batch)\n",
      "[training] step:0140, loss:2.063195 accuracy:0.343750 (679.3 examples/sec; 0.188 sec/batch)\n",
      "[training] step:0150, loss:2.178088 accuracy:0.242188 (681.5 examples/sec; 0.188 sec/batch)\n",
      "[training] step:0160, loss:2.045511 accuracy:0.304688 (649.9 examples/sec; 0.197 sec/batch)\n",
      "[training] step:0170, loss:1.963489 accuracy:0.367188 (678.2 examples/sec; 0.189 sec/batch)\n",
      "[training] step:0180, loss:2.073240 accuracy:0.335938 (667.7 examples/sec; 0.192 sec/batch)\n",
      "[training] step:0190, loss:1.935318 accuracy:0.335938 (697.6 examples/sec; 0.183 sec/batch)\n",
      "[training] step:0200, loss:2.026557 accuracy:0.312500 (682.2 examples/sec; 0.188 sec/batch)\n",
      "[training] step:0210, loss:1.954150 accuracy:0.257812 (680.2 examples/sec; 0.188 sec/batch)\n",
      "[training] step:0220, loss:1.955683 accuracy:0.335938 (643.8 examples/sec; 0.199 sec/batch)\n",
      "[training] step:0230, loss:1.857174 accuracy:0.367188 (685.6 examples/sec; 0.187 sec/batch)\n",
      "[training] step:0240, loss:1.959834 accuracy:0.375000 (690.0 examples/sec; 0.185 sec/batch)\n",
      "[training] step:0250, loss:1.819421 accuracy:0.429688 (653.2 examples/sec; 0.196 sec/batch)\n",
      "[training] step:0260, loss:1.984809 accuracy:0.367188 (650.4 examples/sec; 0.197 sec/batch)\n",
      "[training] step:0270, loss:1.795221 accuracy:0.367188 (646.2 examples/sec; 0.198 sec/batch)\n",
      "[training] step:0280, loss:1.894965 accuracy:0.382812 (676.1 examples/sec; 0.189 sec/batch)\n",
      "[training] step:0290, loss:1.832433 accuracy:0.359375 (681.3 examples/sec; 0.188 sec/batch)\n",
      "[training] step:0300, loss:1.775679 accuracy:0.390625 (646.2 examples/sec; 0.198 sec/batch)\n",
      "[training] step:0310, loss:1.735597 accuracy:0.398438 (646.3 examples/sec; 0.198 sec/batch)\n",
      "[training] step:0320, loss:1.937563 accuracy:0.351562 (683.2 examples/sec; 0.187 sec/batch)\n",
      "[training] step:0330, loss:1.715868 accuracy:0.445312 (655.0 examples/sec; 0.195 sec/batch)\n",
      "[training] step:0340, loss:1.713353 accuracy:0.406250 (655.7 examples/sec; 0.195 sec/batch)\n",
      "[training] step:0350, loss:1.695698 accuracy:0.390625 (669.9 examples/sec; 0.191 sec/batch)\n",
      "[training] step:0360, loss:1.751547 accuracy:0.359375 (660.0 examples/sec; 0.194 sec/batch)\n",
      "[training] step:0370, loss:1.856307 accuracy:0.312500 (687.4 examples/sec; 0.186 sec/batch)\n",
      "[training] step:0380, loss:1.755555 accuracy:0.429688 (650.9 examples/sec; 0.197 sec/batch)\n",
      "[training] step:0390, loss:1.652620 accuracy:0.437500 (675.1 examples/sec; 0.190 sec/batch)\n",
      "[training] step:0400, loss:1.732463 accuracy:0.429688 (676.8 examples/sec; 0.189 sec/batch)\n",
      "[training] step:0410, loss:1.646762 accuracy:0.445312 (647.7 examples/sec; 0.198 sec/batch)\n",
      "[training] step:0420, loss:1.623223 accuracy:0.421875 (676.7 examples/sec; 0.189 sec/batch)\n",
      "[training] step:0430, loss:1.821667 accuracy:0.367188 (654.8 examples/sec; 0.195 sec/batch)\n",
      "[training] step:0440, loss:1.620400 accuracy:0.507812 (690.6 examples/sec; 0.185 sec/batch)\n",
      "[training] step:0450, loss:1.727315 accuracy:0.445312 (659.4 examples/sec; 0.194 sec/batch)\n",
      "[training] step:0460, loss:1.696301 accuracy:0.421875 (654.2 examples/sec; 0.196 sec/batch)\n",
      "[training] step:0470, loss:1.746176 accuracy:0.398438 (629.5 examples/sec; 0.203 sec/batch)\n",
      "[training] step:0480, loss:1.648091 accuracy:0.429688 (661.2 examples/sec; 0.194 sec/batch)\n",
      "[training] step:0490, loss:1.642135 accuracy:0.476562 (681.2 examples/sec; 0.188 sec/batch)\n",
      "[training] step:0500, loss:1.668469 accuracy:0.398438 (677.8 examples/sec; 0.189 sec/batch)\n",
      "[training] step:0510, loss:1.707311 accuracy:0.445312 (662.5 examples/sec; 0.193 sec/batch)\n",
      "[training] step:0520, loss:1.633925 accuracy:0.445312 (676.8 examples/sec; 0.189 sec/batch)\n",
      "[training] step:0530, loss:1.662158 accuracy:0.468750 (683.4 examples/sec; 0.187 sec/batch)\n",
      "[training] step:0540, loss:1.464878 accuracy:0.546875 (682.6 examples/sec; 0.188 sec/batch)\n",
      "[training] step:0550, loss:1.614205 accuracy:0.367188 (644.8 examples/sec; 0.198 sec/batch)\n",
      "[training] step:0560, loss:1.609169 accuracy:0.437500 (676.5 examples/sec; 0.189 sec/batch)\n",
      "[training] step:0570, loss:1.522421 accuracy:0.546875 (688.1 examples/sec; 0.186 sec/batch)\n",
      "[training] step:0580, loss:1.565829 accuracy:0.437500 (682.3 examples/sec; 0.188 sec/batch)\n",
      "[training] step:0590, loss:1.556024 accuracy:0.445312 (663.6 examples/sec; 0.193 sec/batch)\n",
      "[training] step:0600, loss:1.591638 accuracy:0.445312 (674.9 examples/sec; 0.190 sec/batch)\n",
      "[training] step:0610, loss:1.618413 accuracy:0.382812 (655.7 examples/sec; 0.195 sec/batch)\n",
      "[training] step:0620, loss:1.580069 accuracy:0.468750 (654.8 examples/sec; 0.195 sec/batch)\n",
      "[training] step:0630, loss:1.698373 accuracy:0.445312 (620.7 examples/sec; 0.206 sec/batch)\n",
      "[training] step:0640, loss:1.527983 accuracy:0.492188 (669.0 examples/sec; 0.191 sec/batch)\n",
      "[training] step:0650, loss:1.681706 accuracy:0.382812 (688.6 examples/sec; 0.186 sec/batch)\n",
      "[training] step:0660, loss:1.533011 accuracy:0.484375 (654.0 examples/sec; 0.196 sec/batch)\n",
      "[training] step:0670, loss:1.739514 accuracy:0.390625 (658.4 examples/sec; 0.194 sec/batch)\n",
      "[training] step:0680, loss:1.728330 accuracy:0.429688 (682.4 examples/sec; 0.188 sec/batch)\n",
      "[training] step:0690, loss:1.635452 accuracy:0.429688 (685.4 examples/sec; 0.187 sec/batch)\n",
      "[training] step:0700, loss:1.678825 accuracy:0.445312 (647.4 examples/sec; 0.198 sec/batch)\n",
      "[training] step:0710, loss:1.502955 accuracy:0.468750 (650.4 examples/sec; 0.197 sec/batch)\n",
      "[training] step:0720, loss:1.435205 accuracy:0.570312 (696.2 examples/sec; 0.184 sec/batch)\n",
      "[training] step:0730, loss:1.632101 accuracy:0.460938 (643.0 examples/sec; 0.199 sec/batch)\n",
      "[training] step:0740, loss:1.389365 accuracy:0.531250 (692.5 examples/sec; 0.185 sec/batch)\n",
      "[training] step:0750, loss:1.521382 accuracy:0.445312 (689.5 examples/sec; 0.186 sec/batch)\n",
      "[training] step:0760, loss:1.482451 accuracy:0.515625 (648.8 examples/sec; 0.197 sec/batch)\n",
      "[training] step:0770, loss:1.576569 accuracy:0.445312 (691.6 examples/sec; 0.185 sec/batch)\n",
      "[training] step:0780, loss:1.528643 accuracy:0.523438 (678.0 examples/sec; 0.189 sec/batch)\n",
      "[training] step:0790, loss:1.450477 accuracy:0.507812 (654.7 examples/sec; 0.195 sec/batch)\n",
      "[training] step:0800, loss:1.548164 accuracy:0.460938 (668.1 examples/sec; 0.192 sec/batch)\n",
      "[training] step:0810, loss:1.561011 accuracy:0.492188 (660.7 examples/sec; 0.194 sec/batch)\n",
      "[training] step:0820, loss:1.362686 accuracy:0.609375 (636.8 examples/sec; 0.201 sec/batch)\n",
      "[training] step:0830, loss:1.413716 accuracy:0.484375 (680.4 examples/sec; 0.188 sec/batch)\n",
      "[training] step:0840, loss:1.544703 accuracy:0.492188 (610.0 examples/sec; 0.210 sec/batch)\n",
      "[training] step:0850, loss:1.368916 accuracy:0.539062 (680.8 examples/sec; 0.188 sec/batch)\n",
      "[training] step:0860, loss:1.402310 accuracy:0.531250 (682.4 examples/sec; 0.188 sec/batch)\n",
      "[training] step:0870, loss:1.386173 accuracy:0.523438 (650.2 examples/sec; 0.197 sec/batch)\n",
      "[training] step:0880, loss:1.318139 accuracy:0.578125 (665.6 examples/sec; 0.192 sec/batch)\n",
      "[training] step:0890, loss:1.396026 accuracy:0.546875 (693.3 examples/sec; 0.185 sec/batch)\n",
      "[training] step:0900, loss:1.579259 accuracy:0.453125 (636.7 examples/sec; 0.201 sec/batch)\n",
      "[training] step:0910, loss:1.563988 accuracy:0.476562 (654.7 examples/sec; 0.196 sec/batch)\n",
      "[training] step:0920, loss:1.431172 accuracy:0.554688 (681.7 examples/sec; 0.188 sec/batch)\n",
      "[training] step:0930, loss:1.300155 accuracy:0.554688 (682.2 examples/sec; 0.188 sec/batch)\n",
      "[training] step:0940, loss:1.347952 accuracy:0.523438 (692.4 examples/sec; 0.185 sec/batch)\n",
      "[training] step:0950, loss:1.540709 accuracy:0.531250 (653.5 examples/sec; 0.196 sec/batch)\n",
      "[training] step:0960, loss:1.401910 accuracy:0.523438 (692.0 examples/sec; 0.185 sec/batch)\n",
      "[training] step:0970, loss:1.646040 accuracy:0.406250 (680.1 examples/sec; 0.188 sec/batch)\n",
      "[training] step:0980, loss:1.423570 accuracy:0.523438 (647.5 examples/sec; 0.198 sec/batch)\n",
      "[training] step:0990, loss:1.518084 accuracy:0.484375 (681.5 examples/sec; 0.188 sec/batch)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "with tf.Session() as sess:\n",
    "    network = Cifar10Architecture(sess)\n",
    "    train_op, loss, accuracy = network.train(batch.images, batch.labels)\n",
    "    summary_op = tf.merge_all_summaries()\n",
    "    summary_writer = tf.train.SummaryWriter('/tmp/cifar10', graph_def=sess.graph_def)\n",
    "\n",
    "    sess.run( tf.initialize_all_variables() )\n",
    "    reader.start(sess)\n",
    "    \n",
    "    try:\n",
    "        for step in range(1000):\n",
    "            start_time = time.time()\n",
    "            _ = sess.run([train_op, loss, accuracy])\n",
    "            duration = time.time() - start_time\n",
    "            \n",
    "            if step%10 == 0:\n",
    "                num_examples_per_step = 128\n",
    "                examples_per_sec = num_examples_per_step / duration\n",
    "                sec_per_batch = float(duration)\n",
    "                print '[training] step:%04d, loss:%.6f accuracy:%.6f (%.1f examples/sec; %.3f sec/batch)'%(step, _[1], _[2], examples_per_sec, sec_per_batch)\n",
    "                \n",
    "            if step % 100 == 0:\n",
    "                summary_str = sess.run(summary_op)\n",
    "                summary_writer.add_summary(summary_str, step)\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training -- epoch limit reached')\n",
    "    finally:\n",
    "        reader.stop()\n",
    "    \n",
    "    reader.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
